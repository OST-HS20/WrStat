\section{Regression}
\subsection{Regressionskoeffizient}\script{76}
Regressionskoeffizient beschreibt wie gut eine Regression ist:
\[
\frac{\var(Y-aX-B)}{\var(Y)} = 1 - \underbrace{\frac{\cov(X, Y)^2}{\var(X)\var(Y)}}_{r^2}
\]
Regression wird besser, wenn $r^2$ nahe bei $1$ ist, also $r \in [-1,1]$~\\
\includegraphics[width=0.9\linewidth]{Images/regressionskoeffizient}

Die Regressionsgerade $y = ax + b$ kann durch Least Square oder mit folgenden Formelen gefunden werden:
\[
a = \frac{\cov(X, Y)}{\var(X)} \qquad b = E(Y) - aE(X)
\]
\noindent\textbf{Beispiel} Siehe Kapitel \ref{regression}

\subsection{Least Square}
Findet eine Gerade welche die Varianz, Quadratischer Abstand von Gerade, minimiert. 
\begin{center}
	\begin{minipage}{0.20\textwidth}
		\begin{center}
			\includegraphics[width=\linewidth,keepaspectratio=true]{Images/leastsquare}\\
		\end{center}
	\end{minipage}%%% to prevent a space
	\begin{minipage}{0.3\textwidth}
		\[\textcolor{red}{\vec{x}} = (A^TA)^{-1}A^T\vec{b}\]
	\end{minipage}
\end{center}

\noindent
Beispiel f√ºr \textbf{nicht Lineares System} ($b\neq0$): $y_i = \textcolor{red}{a}x_i + \textcolor{red}{b}$.
\[
\underbrace{\begin{pmatrix}
		x_1 & 1 \\
		x_2 & 1 \\
		\vdots & \vdots \\
		x_n & 1
\end{pmatrix}}_{\scriptsize{A}}
\cdot
\underbrace{\begin{pmatrix}
		\textcolor{red}{a} \\
		\textcolor{red}{b}
\end{pmatrix}}_{\scriptsize{\textcolor{red}{\vec{x}}}}
=
\underbrace{\begin{pmatrix}
		y_1 \\
		y_2 \\
		\vdots \\
		y_n
\end{pmatrix}}_{\scriptsize{\vec{b}}}
\]